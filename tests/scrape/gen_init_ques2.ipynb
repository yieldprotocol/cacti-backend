{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.base import BaseOutputParser\n",
    "\n",
    "sys.path.insert(0, r'C:\\Users\\HARSH\\Documents\\chatweb3-backend')\n",
    "from utils import *\n",
    "set_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = \\\n",
    "'''\n",
    "Cryptocurrency wallets\n",
    "Cryptocurrency exchanges\n",
    "Smart contracts\n",
    "Decentralized applications (Dapps)\n",
    "Mining hardware\n",
    "Mining pools\n",
    "Blockchain explorers\n",
    "Hashrate calculators\n",
    "Cryptocurrency payment processors\n",
    "Decentralized identity solutions\n",
    "Prediction markets\n",
    "Governance platforms\n",
    "Interoperability solutions\n",
    "Security solutions\n",
    "Custody solutions\n",
    "Data analytics solutions\n",
    "Network monitoring solutions\n",
    "Blockchain development platforms\n",
    "Crypto-gaming platforms\n",
    "Blockchain-as-a-Service (BaaS) solutions\n",
    "Non-Fungible Tokens (NFTs)\n",
    "Decentralized Finance (DeFi) platforms\n",
    "Stablecoins\n",
    "Security Token Offerings (STOs)\n",
    "Initial Coin Offerings (ICOs)\n",
    "Crypto-to-Fiat Gateways\n",
    "Distributed Ledger Technology (DLT)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \\\n",
    "'''Find 100 most asked questions on internet on \"{tool}\". Please try to be diverse and avoid repetition.'''\n",
    "\n",
    "class ChatOutputParser(BaseOutputParser):\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        \"\"\"Return the type key.\"\"\"\n",
    "        return \"chat_output_parser\"\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        text = text.strip()\n",
    "        text = re.sub(r\"\\d+. \", '', text)\n",
    "        text = text.split('\\n')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0.8, max_tokens=-1,\n",
    ")\n",
    "output_parser = ChatOutputParser()\n",
    "web_ques_prompt = PromptTemplate(\n",
    "    input_variables=[\"tool\"],\n",
    "    template=TEMPLATE,\n",
    "    output_parser=output_parser,\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=web_ques_prompt, verbose=False)\n",
    "\n",
    "all_ques = []\n",
    "for t in TOOLS.strip().split('\\n'):\n",
    "    all_ques.extend(chain.apply_and_parse([{\"tool\": t}])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"init_questions2.txt\", 'w') as output:\n",
    "    for row in all_ques:\n",
    "        output.write(str(row) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a50c67c2899eff48b42ce193594db3f0465d411cbcbdad9a91476e0c1ace7634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

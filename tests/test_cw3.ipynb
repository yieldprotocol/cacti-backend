{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0a89d-dab2-4942-a870-8fbffbe597c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Callable, Generator\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.base import BaseOutputParser\n",
    "from langchain.agents import load_tools, Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from chat.base import BaseChat, ChatHistory, Response\n",
    "from chat.widget_search import ChatOutputParser, WIDGET_INSTRUCTION, SEARCH_INSTRUCTION, TEMPLATE, IDENTIFY_TEMPLATE\n",
    "from chat.base import *\n",
    "from index.weaviate import *\n",
    "from index.widgets import *\n",
    "from utils import *\n",
    "from config import *\n",
    "from system import *\n",
    "from tools import *\n",
    "\n",
    "set_api_key()\n",
    "\n",
    "def send_message(resp, before_message_id=None, last_chat_message_id=None):\n",
    "    if resp.operation == 'replace':\n",
    "        print(resp.response)\n",
    "    return 1\n",
    "\n",
    "system = initialize(default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93870fb7-57b9-44f4-bdba-cf580fe1694f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = ChatHistory([], uuid.UUID, '0x123243242')\n",
    "system.chat.receive_input(history, \"what is the price of ETH\", send_message, uuid.UUID, uuid.UUID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc9672c6",
   "metadata": {},
   "source": [
    "### Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f546873",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''You are a web3 widget tool. You have access to a list of widget magic commands that you can delegate work to, by invoking them and chaining them together, to provide a response to an input query. Magic commands have the structure \"<|command(parameter1, parameter2, ...)|>\" specifying the command and its input parameters. They can only be used with all parameters having known and assigned values, otherwise, they have to be kept secret. The command may either have a display- or a fetch- prefix. When you return a display- command, the user will see data, an interaction box, or other inline item rendered in its place. When you return a fetch- command, data is fetched over an API and injected in place. Users cannot type or use magic commands, so do not tell them to use them. Fill in the command with parameters as inferred from the input. If there are missing parameters, do not use magic commands but mention what parameters are needed instead. If there is no appropriate widget available, explain that more information is needed. Do not make up a non-existent widget magic command, only use the applicable ones for the situation, and only if all parameters are available. You might need to use the output of widget magic commands as the input to another to get your final answer. Here are the widgets that may be relevant:\n",
    "---\n",
    "Widget magic command: <|fetch-price({baseToken},{quoteToken})|>\n",
    "Description of widget: This widget is used to get the price of a token. Note, when the quoteToken isn't explicitly specified assume it to be USD.\n",
    "Required parameters:\n",
    "-{baseToken}: token to get the price of\n",
    "-{quoteToken}: token to use as units for price\n",
    "Return value description:\n",
    "-price of a base token in units of a quote token.\n",
    "---\n",
    "Widget magic command: <|fetch-my-balance({token})|>\n",
    "Description of widget: This widget is used when we need the balance of a token in the user's connected wallet\n",
    "Required parameters:\n",
    "-{token}: token to get the balance of.\n",
    "Return value description:\n",
    "-balance of a token in connected wallet, in decimal units\n",
    "---\n",
    "Use the following format:\n",
    "\n",
    "## Tool Input: given a query which you have to rephrase, explicitly restating the task without pronouns and restating details based on the conversation history and new input. Restate verbatim ALL details/names/figures/facts/etc from past observations relevant to the task and ALL related entities.\n",
    "## Widget Command: most relevant widget magic command to respond to Tool Input\n",
    "## Known Parameters: parameter-value pairs representing inputs to the above widget magic command\n",
    "## Response: return the widget magic command with ALL its respective input parameter values (omit parameter names)\n",
    "\n",
    "## Tool Input: I want to get the price of Ethereum in terms of USD.\n",
    "## Widget Command:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceTextGenInference\n",
    "from langchain.callbacks import streaming_stdout\n",
    "from text_generation import Client\n",
    "\n",
    "callbacks = [streaming_stdout.StreamingStdOutCallbackHandler()]\n",
    "streaming_kwargs = dict(\n",
    "            stream=True,\n",
    "            callbacks=callbacks,\n",
    "        ) \n",
    "\n",
    "inference_server_url = HUGGINGFACE_INFERENCE_ENDPOINT\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "client = Client(inference_server_url, headers=headers)\n",
    "llm = HuggingFaceTextGenInference(\n",
    "    inference_server_url=inference_server_url,\n",
    "    max_new_tokens=10,\n",
    "    temperature=0.1, # should be strictly positive\n",
    "    **streaming_kwargs,\n",
    ")\n",
    "llm.client = client\n",
    "print(llm(\"What is Deep Learning?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
